{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"./mnist_train.csv\", sep=\",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   775  776  777  778  \\\n",
       "0    5    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2    4    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "3    1    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4    9    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.loc[:, 1:] /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data_frame.loc[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128    0.200000\n",
       "129    0.623529\n",
       "130    0.992157\n",
       "131    0.623529\n",
       "132    0.196078\n",
       "155    0.188235\n",
       "156    0.933333\n",
       "157    0.988235\n",
       "158    0.988235\n",
       "159    0.988235\n",
       "160    0.929412\n",
       "182    0.211765\n",
       "183    0.890196\n",
       "184    0.992157\n",
       "185    0.988235\n",
       "186    0.937255\n",
       "187    0.913725\n",
       "188    0.988235\n",
       "189    0.223529\n",
       "190    0.023529\n",
       "208    0.039216\n",
       "209    0.235294\n",
       "210    0.878431\n",
       "211    0.988235\n",
       "212    0.992157\n",
       "213    0.988235\n",
       "214    0.792157\n",
       "215    0.329412\n",
       "216    0.988235\n",
       "217    0.992157\n",
       "         ...   \n",
       "577    0.874510\n",
       "578    0.654902\n",
       "579    0.219608\n",
       "595    0.333333\n",
       "596    0.988235\n",
       "597    0.988235\n",
       "598    0.988235\n",
       "599    0.898039\n",
       "600    0.843137\n",
       "601    0.988235\n",
       "602    0.988235\n",
       "603    0.988235\n",
       "604    0.768627\n",
       "605    0.509804\n",
       "623    0.109804\n",
       "624    0.780392\n",
       "625    0.988235\n",
       "626    0.988235\n",
       "627    0.992157\n",
       "628    0.988235\n",
       "629    0.988235\n",
       "630    0.913725\n",
       "631    0.568627\n",
       "652    0.098039\n",
       "653    0.501961\n",
       "654    0.988235\n",
       "655    0.992157\n",
       "656    0.988235\n",
       "657    0.552941\n",
       "658    0.145098\n",
       "Name: 1, Length: 176, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[tmp != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paulina\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data=data_frame.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=data[0,1:].reshape((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(data_matrix, index):\n",
    "\timage=data_matrix[index,1:].reshape((28,28))\n",
    "\tplt.imshow(image)\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    \n",
    "    def __init__(self, train_data, hidden_layer_neurons_num, learning_rate = 0.05, activation_functions = None):\n",
    "        self.number_of_classes = 10\n",
    "        self.train_data = train_data\n",
    "        self.learning_rate = learning_rate\n",
    "        train_data_without_labels = train_data[:,1:]\n",
    "        self.input_neurons_num = train_data_without_labels.shape[0] \\\n",
    "            if len(train_data_without_labels.shape) == 1 \\\n",
    "            else train_data_without_labels.shape[1]\n",
    "        self.neurons_num_per_layer = [self.input_neurons_num] + hidden_layer_neurons_num + [self.number_of_classes]\n",
    "        self.layers_num = len(self.neurons_num_per_layer)\n",
    "        self.activation_functions = [lambda x: self.sigmoid_function(x)] * (self.layers_num - 2) + \\\n",
    "            [lambda x: self.softmax_function(x)] \n",
    "        self.weight_list = [np.random.randn(next_layer_num, current_layer_num) \\\n",
    "                       for (current_layer_num, next_layer_num) in \\\n",
    "                            zip(self.neurons_num_per_layer, self.neurons_num_per_layer[1:])]\n",
    "        \n",
    "        self.bias_list = [np.random.randn(layer_num,1) for layer_num in self.neurons_num_per_layer[1:]]\n",
    "        \n",
    "    \n",
    "    def main(self, batch_size):\n",
    "        train_batches = self.create_train_batches(batch_size)\n",
    "        self.feed_forward(train_batches)\n",
    "        # TODO: finish\n",
    "        \n",
    "  \n",
    "\n",
    "    #uwaga feedforward można zrobić macierzowo, ale backprop trzeba dla pojedynczych rekordów\n",
    "    def feed_forward(self, train_batches):\n",
    "        for train_batch in train_batches:\n",
    "            labels = self.one_hot_encoded(train_batch[:, 0:1])\n",
    "            train_batch_features = train_batch[:, 1:]\n",
    "            \n",
    "            \n",
    "            #forward\n",
    "            for i in range (len(train_batch)): #rekord\n",
    "                u = []\n",
    "                layer_output = [train_batch_features[i,:]]\n",
    "                for activation_function, w, b in zip(self.activation_functions, \\\n",
    "                                                 self.weight_list, \\\n",
    "                                                 self.bias_list):\n",
    "                   \n",
    "                    a=np.matmul(w,layer_output[-1])\n",
    "                    \n",
    "                    u.append(a.reshape(a.shape[0],1) + b)\n",
    "                    print(u[-1].shape)\n",
    "                    layer_output.append(activation_function(u[-1]))\n",
    "                           \n",
    "                \n",
    "                #backprop\n",
    "                label=labels[:,i].reshape(10,1)\n",
    "                delta = [(layer_output[-1] - label) * self.softmax_derivative(layer_output[-1], u[-1])] \n",
    "                print(delta[0].shape)\n",
    "                for layer_num in reversed(range(1, self.layers_num-1)):\n",
    "                    print(\"delta {0}\".format(delta[-1].shape))\n",
    "                    print(\"weight_list {0}\".format((self.weight_list[layer_num]).shape))\n",
    "                    print(\"u[layer_num] {0}\".format(u[layer_num].shape))\n",
    "                    print(\"sigm_der {0}\".format(self.sigmoid_derivative(u[layer_num]).shape))\n",
    "                    delta.append(np.matmul(self.weight_list[layer_num].T, delta[-1])*\\\n",
    "                                 self.sigmoid_derivative(u[layer_num-1])) \n",
    "                delta = list(reversed(delta))\n",
    "                              \n",
    "            \n",
    "                grad_w = [np.matmul(delta[0], train_batch_features[i,:].reshape(784,1).T)]\n",
    "                grad_b = delta.copy()\n",
    "                for activ, d, _u in zip(self.activation_functions, delta[1:], u):\n",
    "                    grad_w.append(np.matmul(d,activ(_u).T))\n",
    "                    print(\"GRAD_W {0}\".format((grad_w[-1]).shape))\n",
    "                print('ww')\n",
    "                print(grad_w[0].shape)\n",
    "                print(grad_w[1].shape)\n",
    "                print(grad_w[2].shape)\n",
    "               \n",
    "                \n",
    "                new_weight_list = [(w - self.learning_rate * gw) \\\n",
    "                               for w, gw in zip(self.weight_list, grad_w)]\n",
    "                self.weight_list = new_weight_list\n",
    "            \n",
    "                new_bias_list = [ (b - self.learning_rate * gb) \\\n",
    "                             for b, gb in zip(self.bias_list, grad_b)]\n",
    "                self.bias_list = new_bias_list\n",
    "            \n",
    "    def softmax_derivative(self, probabilities, u):\n",
    "        diff_output=np.zeros([self.number_of_classes, self.number_of_classes])\n",
    "        for row in range (diff_output.shape[0]):\n",
    "            for col in range (diff_output.shape[1]):\n",
    "                if (col==row):\n",
    "                    diff_output[row,col]=probabilities[row,0]*(1-probabilities[col,0])\n",
    "                else:\n",
    "                    diff_output[row,col]=-probabilities[row,0]*probabilities[col,0]\n",
    "        return np.matmul(diff_output,u)\n",
    "                             \n",
    "    def sigmoid_derivative(self, u):\n",
    "        diff_output=u*(1-u)\n",
    "        return diff_output\n",
    "        \n",
    "    def tanh_derivative(self, u):\n",
    "        diff_output=1-(u)^2\n",
    "        return diff_output\n",
    "         \n",
    "    def create_train_batches(self, batch_size):\n",
    "        rows_num = self.train_data.shape[0]\n",
    "        n = int(np.ceil(rows_num / batch_size))\n",
    "        return [self.train_data[(i * batch_size):min((i + 1) * batch_size, rows_num)] for i in range(n)]\n",
    "    \n",
    "    def one_hot_encoded(self, train_labels):\n",
    "        train_labels = train_labels.astype(int)\n",
    "        res = np.zeros((self.number_of_classes, train_labels.shape[0]))\n",
    "        res[train_labels, np.arange(res.shape[1])] = 1\n",
    "        return res\n",
    "        \n",
    "    def sigmoid_function(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def softmax_function(self, x):\n",
    "        return np.exp(x) / np.sum(np.exp(x)) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(data[1:10], [30,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(30, 784), (20, 30), (10, 20)]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[matrix.shape for matrix in net.weight_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.input_neurons_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.bias_list[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 30)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weight_list[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.sigmoid_function(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 785), (2, 785), (2, 785), (2, 785), (1, 785)]"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[matrix.shape for matrix in net.create_train_batches(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(net.softmax_function(np.array([1,2,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09003057, 0.24472847, 0.66524096])"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.softmax_function(np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.one_hot_encoded(np.array([1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size\n",
      "(10, 1)\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "fft\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "aaa (10, 1)\n",
      "wazne\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "tu\n",
      "2\n",
      "delta (10, 1)\n",
      "weight_list (10, 20)\n",
      "u[layer_num] (10, 1)\n",
      "shape\n",
      "(10, 1)\n",
      "sigm_der (10, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "tu\n",
      "1\n",
      "delta (20, 1)\n",
      "weight_list (20, 30)\n",
      "u[layer_num] (20, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "sigm_der (20, 1)\n",
      "shape\n",
      "(30, 1)\n",
      "mega\n",
      "3\n",
      "jestem\n",
      "(1, 30)\n",
      "GRAD_W (20, 30)\n",
      "jestem\n",
      "(1, 20)\n",
      "GRAD_W (10, 20)\n",
      "ww\n",
      "(30, 784)\n",
      "(20, 30)\n",
      "(10, 20)\n",
      "size\n",
      "(10, 1)\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "fft\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "aaa (10, 1)\n",
      "wazne\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "tu\n",
      "2\n",
      "delta (10, 1)\n",
      "weight_list (10, 20)\n",
      "u[layer_num] (10, 1)\n",
      "shape\n",
      "(10, 1)\n",
      "sigm_der (10, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "tu\n",
      "1\n",
      "delta (20, 1)\n",
      "weight_list (20, 30)\n",
      "u[layer_num] (20, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "sigm_der (20, 1)\n",
      "shape\n",
      "(30, 1)\n",
      "mega\n",
      "3\n",
      "jestem\n",
      "(1, 30)\n",
      "GRAD_W (20, 30)\n",
      "jestem\n",
      "(1, 20)\n",
      "GRAD_W (10, 20)\n",
      "ww\n",
      "(30, 784)\n",
      "(20, 30)\n",
      "(10, 20)\n",
      "size\n",
      "(10, 1)\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "fft\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "aaa (10, 1)\n",
      "wazne\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "tu\n",
      "2\n",
      "delta (10, 1)\n",
      "weight_list (10, 20)\n",
      "u[layer_num] (10, 1)\n",
      "shape\n",
      "(10, 1)\n",
      "sigm_der (10, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "tu\n",
      "1\n",
      "delta (20, 1)\n",
      "weight_list (20, 30)\n",
      "u[layer_num] (20, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "sigm_der (20, 1)\n",
      "shape\n",
      "(30, 1)\n",
      "mega\n",
      "3\n",
      "jestem\n",
      "(1, 30)\n",
      "GRAD_W (20, 30)\n",
      "jestem\n",
      "(1, 20)\n",
      "GRAD_W (10, 20)\n",
      "ww\n",
      "(30, 784)\n",
      "(20, 30)\n",
      "(10, 20)\n",
      "size\n",
      "(10, 1)\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "fft\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "aaa (10, 1)\n",
      "wazne\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "tu\n",
      "2\n",
      "delta (10, 1)\n",
      "weight_list (10, 20)\n",
      "u[layer_num] (10, 1)\n",
      "shape\n",
      "(10, 1)\n",
      "sigm_der (10, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "tu\n",
      "1\n",
      "delta (20, 1)\n",
      "weight_list (20, 30)\n",
      "u[layer_num] (20, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "sigm_der (20, 1)\n",
      "shape\n",
      "(30, 1)\n",
      "mega\n",
      "3\n",
      "jestem\n",
      "(1, 30)\n",
      "GRAD_W (20, 30)\n",
      "jestem\n",
      "(1, 20)\n",
      "GRAD_W (10, 20)\n",
      "ww\n",
      "(30, 784)\n",
      "(20, 30)\n",
      "(10, 20)\n",
      "size\n",
      "(10, 1)\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "fft\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "aaa (10, 1)\n",
      "wazne\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "tu\n",
      "2\n",
      "delta (10, 1)\n",
      "weight_list (10, 20)\n",
      "u[layer_num] (10, 1)\n",
      "shape\n",
      "(10, 1)\n",
      "sigm_der (10, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "tu\n",
      "1\n",
      "delta (20, 1)\n",
      "weight_list (20, 30)\n",
      "u[layer_num] (20, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "sigm_der (20, 1)\n",
      "shape\n",
      "(30, 1)\n",
      "mega\n",
      "3\n",
      "jestem\n",
      "(1, 30)\n",
      "GRAD_W (20, 30)\n",
      "jestem\n",
      "(1, 20)\n",
      "GRAD_W (10, 20)\n",
      "ww\n",
      "(30, 784)\n",
      "(20, 30)\n",
      "(10, 20)\n",
      "size\n",
      "(10, 1)\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "fft\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "aaa (10, 1)\n",
      "wazne\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "tu\n",
      "2\n",
      "delta (10, 1)\n",
      "weight_list (10, 20)\n",
      "u[layer_num] (10, 1)\n",
      "shape\n",
      "(10, 1)\n",
      "sigm_der (10, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "tu\n",
      "1\n",
      "delta (20, 1)\n",
      "weight_list (20, 30)\n",
      "u[layer_num] (20, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "sigm_der (20, 1)\n",
      "shape\n",
      "(30, 1)\n",
      "mega\n",
      "3\n",
      "jestem\n",
      "(1, 30)\n",
      "GRAD_W (20, 30)\n",
      "jestem\n",
      "(1, 20)\n",
      "GRAD_W (10, 20)\n",
      "ww\n",
      "(30, 784)\n",
      "(20, 30)\n",
      "(10, 20)\n",
      "size\n",
      "(10, 1)\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "fft\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "aaa (10, 1)\n",
      "wazne\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "tu\n",
      "2\n",
      "delta (10, 1)\n",
      "weight_list (10, 20)\n",
      "u[layer_num] (10, 1)\n",
      "shape\n",
      "(10, 1)\n",
      "sigm_der (10, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "tu\n",
      "1\n",
      "delta (20, 1)\n",
      "weight_list (20, 30)\n",
      "u[layer_num] (20, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "sigm_der (20, 1)\n",
      "shape\n",
      "(30, 1)\n",
      "mega\n",
      "3\n",
      "jestem\n",
      "(1, 30)\n",
      "GRAD_W (20, 30)\n",
      "jestem\n",
      "(1, 20)\n",
      "GRAD_W (10, 20)\n",
      "ww\n",
      "(30, 784)\n",
      "(20, 30)\n",
      "(10, 20)\n",
      "size\n",
      "(10, 1)\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "fft\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "aaa (10, 1)\n",
      "wazne\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "tu\n",
      "2\n",
      "delta (10, 1)\n",
      "weight_list (10, 20)\n",
      "u[layer_num] (10, 1)\n",
      "shape\n",
      "(10, 1)\n",
      "sigm_der (10, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "tu\n",
      "1\n",
      "delta (20, 1)\n",
      "weight_list (20, 30)\n",
      "u[layer_num] (20, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "sigm_der (20, 1)\n",
      "shape\n",
      "(30, 1)\n",
      "mega\n",
      "3\n",
      "jestem\n",
      "(1, 30)\n",
      "GRAD_W (20, 30)\n",
      "jestem\n",
      "(1, 20)\n",
      "GRAD_W (10, 20)\n",
      "ww\n",
      "(30, 784)\n",
      "(20, 30)\n",
      "(10, 20)\n",
      "size\n",
      "(10, 1)\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "fft\n",
      "(30, 1)\n",
      "(20, 1)\n",
      "(10, 1)\n",
      "aaa (10, 1)\n",
      "wazne\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "(10, 1)\n",
      "tu\n",
      "2\n",
      "delta (10, 1)\n",
      "weight_list (10, 20)\n",
      "u[layer_num] (10, 1)\n",
      "shape\n",
      "(10, 1)\n",
      "sigm_der (10, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "tu\n",
      "1\n",
      "delta (20, 1)\n",
      "weight_list (20, 30)\n",
      "u[layer_num] (20, 1)\n",
      "shape\n",
      "(20, 1)\n",
      "sigm_der (20, 1)\n",
      "shape\n",
      "(30, 1)\n",
      "mega\n",
      "3\n",
      "jestem\n",
      "(1, 30)\n",
      "GRAD_W (20, 30)\n",
      "jestem\n",
      "(1, 20)\n",
      "GRAD_W (10, 20)\n",
      "ww\n",
      "(30, 784)\n",
      "(20, 30)\n",
      "(10, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paulina\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:120: RuntimeWarning: overflow encountered in multiply\n",
      "C:\\Users\\Paulina\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: overflow encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "net.main(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function __main__.Network.__init__.<locals>.<lambda>(x)>,\n",
       " <function __main__.Network.__init__.<locals>.<lambda>(x)>,\n",
       " <function __main__.Network.__init__.<locals>.<lambda>(x)>]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.neurons_num_per_layer\n",
    "net.activation_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(net.create_train_batches(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.back_propagation(net.feed_forward(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train_data[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def sigmoid_derivative( u):\n",
    "        diff_output=u*(1-u)\n",
    "        return diff_output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_derivative(probabilities):\n",
    "    #probabilities = np.asarray(probabilities[0]).reshape(probabilities.shape[1])\n",
    "    diff_output=np.zeros([3,3])\n",
    "    for row in range (diff_output.shape[0]):\n",
    "        for col in range (diff_output.shape[1]):\n",
    "            if (col==row):\n",
    "                print(\"res {0}\".format(probabilities[row]))\n",
    "                diff_output[col,row]=probabilities[row]*(1-probabilities[col])\n",
    "            else:\n",
    "                diff_output[col,row]=-probabilities[row]*probabilities[col]\n",
    "    return diff_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=sigmoid_derivative(np.array([3,2,4]))\n",
    "e=softmax_derivative(np.array([4,3,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=np.array([1,2,3]).reshape(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n[1,0]\n",
    "n[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= np.random.random_sample((5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.array([2,3,4]).reshape(3,1)\n",
    "c=np.array([2,1,1]).reshape(3,1)\n",
    "d=b*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [3],\n",
       "       [4]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(b.shape)\n",
    "print(c.shape)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.multiply(b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for  i in reversed(range (1,3)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_num in reversed(range(1, self.layers_num-1)):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
